{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372f74ac-8a36-4b79-944d-9b78ef05563a",
   "metadata": {},
   "source": [
    "## **Phase 1 - Feature Engineering and Model Prep**\n",
    "\n",
    "This notebook transforms chemical structure information into high-quality machine learning features. Building on the curated dataset from the discovery phase, we will generate fingerprint and descriptor-based representations of molecules to enable robust bioactivity modeling.\n",
    "\n",
    "Our goals for this phase are:\n",
    "\n",
    "- Read in our previous phase1_df notebook, reviewing our work and cleaning as necessary.\n",
    "- Compute Morgan fingerprints from SMILES strings to represent molecular substructure.\n",
    "- Generate RDKit-based physicochemical descriptors that capture key QSAR-relevant features.\n",
    "- Perform feature filtering using methods such as VIF and RFE to narrow down the list of features we have generated.\n",
    "- Apply optional preprocessing steps such as outlier detection and collinearity checks.\n",
    "- Save the final feature-engineered dataset for use in the next modeling phase.\n",
    "\n",
    "> These engineered features will power the classifier that predicts bioactivity (IC50 ≤ 3162 nM) against our selected target: **GABA-A receptors** involved in epilepsy treatment.\n",
    "\n",
    "This phase acts as the final staging point before model training begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8cb696c-8679-4777-a2d2-938fb0d4e09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with shape: (2850, 11)\n",
      "   molregno standard_type standard_units  \\\n",
      "0   1634114          IC50             nM   \n",
      "1    942456          IC50             nM   \n",
      "2   1633993          IC50             nM   \n",
      "3   1633991          IC50             nM   \n",
      "4   1634151          IC50             nM   \n",
      "5   1633990          IC50             nM   \n",
      "6   1633994          IC50             nM   \n",
      "7      9842          IC50             nM   \n",
      "8       721          IC50             nM   \n",
      "9      7395          IC50             nM   \n",
      "\n",
      "                                    canonical_smiles  mw_freebase  alogp  hba  \\\n",
      "0               O=c1c2cnc3cccc(O)c3c2[nH]n1-c1ccccc1       277.28   2.57  4.0   \n",
      "1      CCOC(=O)c1ncc2[nH]c3ccc(OCc4ccccc4)cc3c2c1COC       390.44   4.62  5.0   \n",
      "2      O=c1c2cnc3cccc(OCc4ccccc4)c3c2[nH]n1-c1ccccc1       367.41   4.45  4.0   \n",
      "3            COc1cccc2ncc3c(=O)n(-c4ccccc4)[nH]c3c12       291.31   2.88  4.0   \n",
      "4      O=c1c2cnc3ccc(OCc4ccccc4)cc3c2[nH]n1-c1ccccc1       367.41   4.45  4.0   \n",
      "5      O=c1c2cnc3c(OCc4ccccc4)cccc3c2[nH]n1-c1ccccc1       367.41   4.45  4.0   \n",
      "6  O=c1c2cnc3ccc(OCc4ccccc4)cc3c2[nH]n1-c1ccc(Cl)cc1       401.85   5.10  4.0   \n",
      "7                    CCOC(=O)c1cc2c3ccccc3nc-2c[nH]1       240.26   2.84  3.0   \n",
      "8                CN1C(=O)CN=C(c2ccccc2)c2cc(Cl)ccc21       284.75   3.15  2.0   \n",
      "9             CCOC(=O)c1[nH]cc2nc3ccc(OC)cc3c-2c1COC       314.34   3.00  5.0   \n",
      "\n",
      "   hbd  rtb  qed_weighted  active  \n",
      "0  2.0  1.0          0.56       1  \n",
      "1  1.0  7.0          0.47       1  \n",
      "2  1.0  4.0          0.51       0  \n",
      "3  1.0  2.0          0.62       1  \n",
      "4  1.0  4.0          0.51       1  \n",
      "5  1.0  4.0          0.51       1  \n",
      "6  1.0  4.0          0.46       1  \n",
      "7  1.0  2.0          0.70       1  \n",
      "8  0.0  1.0          0.79       1  \n",
      "9  1.0  5.0          0.73       1  \n",
      "           molregno  mw_freebase        alogp          hba          hbd  \\\n",
      "count  2.850000e+03  2850.000000  2849.000000  2849.000000  2849.000000   \n",
      "mean   2.869825e+05   315.976919     3.438487     3.664444     0.995086   \n",
      "std    4.408988e+05    85.888603     1.629243     1.735616     0.899425   \n",
      "min    1.460000e+02    85.110000    -1.560000     0.000000     0.000000   \n",
      "25%    8.319400e+04   271.320000     2.470000     2.000000     0.000000   \n",
      "50%    1.385140e+05   314.340000     3.410000     4.000000     1.000000   \n",
      "75%    2.414152e+05   368.910000     4.440000     5.000000     2.000000   \n",
      "max    2.285888e+06   665.800000     9.760000    11.000000     6.000000   \n",
      "\n",
      "               rtb  qed_weighted       active  \n",
      "count  2849.000000   2849.000000  2850.000000  \n",
      "mean      3.151632      0.619926     0.690526  \n",
      "std       2.688569      0.152943     0.462358  \n",
      "min       0.000000      0.120000     0.000000  \n",
      "25%       1.000000      0.520000     0.000000  \n",
      "50%       3.000000      0.640000     1.000000  \n",
      "75%       4.000000      0.740000     1.000000  \n",
      "max      20.000000      0.940000     1.000000  \n",
      "\n",
      " Active class balance:\n",
      "active\n",
      "1    1968\n",
      "0     882\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the previously saved dataset from our discovery notebook\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "phase1_df = pd.read_csv(\"../data/processed/phase1_df.csv\")\n",
    "\n",
    "# NOTE: Removing 'standard_value' feature column, as since we have our active classifier it is no \n",
    "# longer needed and keeping it would create data leakage downstream.\n",
    "phase1_df = phase1_df.drop(columns = ['standard_value'])\n",
    "\n",
    "# Sanity check - Review shape, first few rows, and describe() call\n",
    "print(f\"Loaded dataset with shape: {phase1_df.shape}\")\n",
    "\n",
    "print(phase1_df.head(10))\n",
    "\n",
    "print(phase1_df.describe())\n",
    "\n",
    "# Review active class balance\n",
    "print(\"\\n Active class balance:\")\n",
    "print(phase1_df['active'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4431db6-c14f-4ca2-a23e-3550c49b4f3e",
   "metadata": {},
   "source": [
    "#### Reviewing the describe() call above I can see that our Count amounts don't match.  Also we have some noticeable values in the standard_value that we can now clean up.  We were already aware of these values previously in our work beforehand, and now is the time to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afc8c88-365a-45be-a5f4-a26853179aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molregno            0\n",
      "standard_type       0\n",
      "standard_units      0\n",
      "canonical_smiles    0\n",
      "mw_freebase         0\n",
      "alogp               1\n",
      "hba                 1\n",
      "hbd                 1\n",
      "rtb                 1\n",
      "qed_weighted        1\n",
      "active              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values check first\n",
    "print(phase1_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e8caf9-eb64-4eb1-ad6a-0c3ff2a1823b",
   "metadata": {},
   "source": [
    "#### Just 1 row for some of the features, we will just remove and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680685ed-550e-4df1-aab6-cab9e3ce479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2849, 11)\n"
     ]
    }
   ],
   "source": [
    "phase1_df = phase1_df.dropna()\n",
    "\n",
    "print(phase1_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f42660-3f65-45a2-b66a-adb9a6dae352",
   "metadata": {},
   "source": [
    "#### Now let's keep moving forward with our agenda and compute Morgan Fingerprints from our canonical_smiles feature column.\n",
    "\n",
    "#### We will be making a function here to convert our SMILES data from the canonical_smiles feature into 2048-bit fingerprints using RDKit.  This will allow the SMILES data to be used in modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c044a2-3085-46c4-a360-96054a14f33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid fingerprints before parsing: 2849 / 2849\n",
      "Final shape with new Morgan Fingerprints added: (2849, 2059)\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Set up the generator\n",
    "morgan_gen = GetMorganGenerator(radius = 2, fpSize = 2048)\n",
    "\n",
    "# Function to convert SMILES to 2048-bit fingerprints\n",
    "def mol_to_fp(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.nan # Will allow the value to be dropped later\n",
    "    fp = morgan_gen.GetFingerprint(mol)\n",
    "    arr = np.zeros((2048,), dtype = int)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "# Apply to existing df\n",
    "fp_array = phase1_df['canonical_smiles'].apply(mol_to_fp)\n",
    "\n",
    "# Drop invalid SMILES rows (if any failed)\n",
    "print(f\"Valid fingerprints before parsing: {fp_array.notnull().sum()} / {len(fp_array)}\")\n",
    "phase1_df = phase1_df[fp_array.notnull()]\n",
    "fp_array = fp_array[fp_array.notnull()]\n",
    "\n",
    "# Prepping the merge with our orginal df, need to stack into a 2D array and then a df\n",
    "fp_matrix = np.stack(fp_array.to_numpy())\n",
    "fp_df = pd.DataFrame(fp_matrix, columns = [f'fp_{i}' for i in range(fp_matrix.shape[1])])\n",
    "\n",
    "# Merge then finally into our phase1_df\n",
    "phase1_df = phase1_df.reset_index(drop=True)\n",
    "fp_df = fp_df.reset_index(drop=True)\n",
    "phase1_df_fp = pd.concat([phase1_df, fp_df], axis = 1)\n",
    "\n",
    "print(f\"Final shape with new Morgan Fingerprints added: {phase1_df_fp.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e126b25-376c-4b5b-aa6a-b9a15b1432a2",
   "metadata": {},
   "source": [
    "#### Good, now we will move on to generating new features with RDKit.  Since we are very early in this project yet we will just do a mass generation in a new separate df, then add our active classifier to later filter down what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a979b01d-26df-400f-ba95-498843a354e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit Raw Descriptor Matrix: (2849, 217)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.493961</td>\n",
       "      <td>12.493961</td>\n",
       "      <td>0.103761</td>\n",
       "      <td>-0.186247</td>\n",
       "      <td>0.561466</td>\n",
       "      <td>11.238095</td>\n",
       "      <td>277.283</td>\n",
       "      <td>266.195</td>\n",
       "      <td>277.085127</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.393112</td>\n",
       "      <td>12.393112</td>\n",
       "      <td>0.250537</td>\n",
       "      <td>-0.451591</td>\n",
       "      <td>0.466310</td>\n",
       "      <td>11.103448</td>\n",
       "      <td>390.439</td>\n",
       "      <td>368.263</td>\n",
       "      <td>390.157957</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.914130</td>\n",
       "      <td>12.914130</td>\n",
       "      <td>0.131053</td>\n",
       "      <td>-0.131053</td>\n",
       "      <td>0.510602</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>367.408</td>\n",
       "      <td>350.272</td>\n",
       "      <td>367.132077</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.623107</td>\n",
       "      <td>12.623107</td>\n",
       "      <td>0.123605</td>\n",
       "      <td>-0.123605</td>\n",
       "      <td>0.617515</td>\n",
       "      <td>11.136364</td>\n",
       "      <td>291.310</td>\n",
       "      <td>278.206</td>\n",
       "      <td>291.100777</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.828693</td>\n",
       "      <td>12.828693</td>\n",
       "      <td>0.119253</td>\n",
       "      <td>-0.119253</td>\n",
       "      <td>0.510602</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>367.408</td>\n",
       "      <td>350.272</td>\n",
       "      <td>367.132077</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.828693</td>\n",
       "      <td>12.828693</td>\n",
       "      <td>0.119253</td>\n",
       "      <td>-0.119253</td>\n",
       "      <td>0.510602</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>367.408</td>\n",
       "      <td>350.272</td>\n",
       "      <td>367.132077</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.880635</td>\n",
       "      <td>12.880635</td>\n",
       "      <td>0.159880</td>\n",
       "      <td>-0.159880</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>11.206897</td>\n",
       "      <td>401.853</td>\n",
       "      <td>385.725</td>\n",
       "      <td>401.093104</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.672440</td>\n",
       "      <td>11.672440</td>\n",
       "      <td>0.342888</td>\n",
       "      <td>-0.342888</td>\n",
       "      <td>0.700597</td>\n",
       "      <td>10.944444</td>\n",
       "      <td>240.262</td>\n",
       "      <td>228.166</td>\n",
       "      <td>240.089878</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.024468</td>\n",
       "      <td>12.024468</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>0.791645</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>284.746</td>\n",
       "      <td>271.642</td>\n",
       "      <td>284.071641</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.210954</td>\n",
       "      <td>12.210954</td>\n",
       "      <td>0.277769</td>\n",
       "      <td>-0.403985</td>\n",
       "      <td>0.732870</td>\n",
       "      <td>11.086957</td>\n",
       "      <td>314.341</td>\n",
       "      <td>296.197</td>\n",
       "      <td>314.126657</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n",
       "0          12.493961       12.493961           0.103761       -0.186247   \n",
       "1          12.393112       12.393112           0.250537       -0.451591   \n",
       "2          12.914130       12.914130           0.131053       -0.131053   \n",
       "3          12.623107       12.623107           0.123605       -0.123605   \n",
       "4          12.828693       12.828693           0.119253       -0.119253   \n",
       "5          12.828693       12.828693           0.119253       -0.119253   \n",
       "6          12.880635       12.880635           0.159880       -0.159880   \n",
       "7          11.672440       11.672440           0.342888       -0.342888   \n",
       "8          12.024468       12.024468           0.028237       -0.028237   \n",
       "9          12.210954       12.210954           0.277769       -0.403985   \n",
       "\n",
       "        qed        SPS    MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
       "0  0.561466  11.238095  277.283         266.195  277.085127   \n",
       "1  0.466310  11.103448  390.439         368.263  390.157957   \n",
       "2  0.510602  11.142857  367.408         350.272  367.132077   \n",
       "3  0.617515  11.136364  291.310         278.206  291.100777   \n",
       "4  0.510602  11.142857  367.408         350.272  367.132077   \n",
       "5  0.510602  11.142857  367.408         350.272  367.132077   \n",
       "6  0.455474  11.206897  401.853         385.725  401.093104   \n",
       "7  0.700597  10.944444  240.262         228.166  240.089878   \n",
       "8  0.791645  14.600000  284.746         271.642  284.071641   \n",
       "9  0.732870  11.086957  314.341         296.197  314.126657   \n",
       "\n",
       "   NumValenceElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0                102.0  ...         0.0           0.0         0.0   \n",
       "1                148.0  ...         0.0           0.0         0.0   \n",
       "2                136.0  ...         0.0           0.0         0.0   \n",
       "3                108.0  ...         0.0           0.0         0.0   \n",
       "4                136.0  ...         0.0           0.0         0.0   \n",
       "5                136.0  ...         0.0           0.0         0.0   \n",
       "6                142.0  ...         0.0           0.0         0.0   \n",
       "7                 90.0  ...         0.0           0.0         0.0   \n",
       "8                100.0  ...         0.0           0.0         0.0   \n",
       "9                120.0  ...         0.0           0.0         0.0   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                0.0           0.0          0.0          0.0           0.0   \n",
       "1                0.0           0.0          0.0          0.0           0.0   \n",
       "2                0.0           0.0          0.0          0.0           0.0   \n",
       "3                0.0           0.0          0.0          0.0           0.0   \n",
       "4                0.0           0.0          0.0          0.0           0.0   \n",
       "5                0.0           0.0          0.0          0.0           0.0   \n",
       "6                0.0           0.0          0.0          0.0           0.0   \n",
       "7                0.0           0.0          0.0          0.0           0.0   \n",
       "8                0.0           0.0          0.0          0.0           0.0   \n",
       "9                0.0           0.0          0.0          0.0           0.0   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  \n",
       "0               0.0      0.0  \n",
       "1               0.0      0.0  \n",
       "2               0.0      0.0  \n",
       "3               0.0      0.0  \n",
       "4               0.0      0.0  \n",
       "5               0.0      0.0  \n",
       "6               0.0      0.0  \n",
       "7               0.0      0.0  \n",
       "8               0.0      0.0  \n",
       "9               0.0      0.0  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.Descriptors import _descList\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "\n",
    "# Get ALL Descriptor names\n",
    "desc_names = [desc[0] for desc in Descriptors._descList]\n",
    "\n",
    "# Filter this list for only non-overlapping ones that we already have in phase1_df_fp\n",
    "existing_features = set(phase1_df_fp.columns)\n",
    "desc_names = [name for name in desc_names if name not in existing_features]\n",
    "\n",
    "# Set up descriptor calculator\n",
    "desc_calc = MolecularDescriptorCalculator(desc_names)\n",
    "\n",
    "# Convert SMILES to molecule (needs fresh call) and calculate descriptors\n",
    "def compute_all_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * len(desc_names)\n",
    "    return list(desc_calc.CalcDescriptors(mol))\n",
    "\n",
    "# Run on the SMILES feature column\n",
    "desc_matrix = phase1_df_fp['canonical_smiles'].apply(compute_all_descriptors)\n",
    "desc_array = np.vstack(desc_matrix)\n",
    "rdkit_raw_df = pd.DataFrame(desc_array, columns=desc_names)\n",
    "\n",
    "# Preview before moving on\n",
    "print(f\"RDKit Raw Descriptor Matrix: {rdkit_raw_df.shape}\")\n",
    "rdkit_raw_df.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c085fc8-e13e-4bbc-babb-04cc8515b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to our new df our active classifier so we can filter\n",
    "rdkit_raw_df['active'] = phase1_df_fp['active'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cebad56-d91e-4b94-b750-a4db593bac8f",
   "metadata": {},
   "source": [
    "#### Good, now that we have our RDKit generated features along with our active classifier target let's do some quick cleanup on our features before we get into filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fadf3e-1bf7-48ad-a50c-f8c8e2be892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping suggested columns: (2849, 207)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that are entirely NaN\n",
    "rdkit_raw_df = rdkit_raw_df.dropna(axis = 1, how = 'all')\n",
    "\n",
    "# Drop columns that are entirely 0 (noted several in our head() call above)\n",
    "rdkit_raw_df = rdkit_raw_df.loc[:, (rdkit_raw_df !=0).any(axis = 0)]\n",
    "\n",
    "print(f\"Shape after dropping suggested columns: {rdkit_raw_df.shape}\")\n",
    "\n",
    "# Below when we ran the plots we came across some inf values, we will clip them rather than remove\n",
    "rdkit_raw_df = rdkit_raw_df.replace([np.inf, -np.inf], np.nan)\n",
    "rdkit_raw_df = rdkit_raw_df.fillna(rdkit_raw_df.mean())\n",
    "\n",
    "# Check for constant columns (perfect multicollinearity) and drop those where std = 0\n",
    "constant_cols = [col for col in rdkit_raw_df.columns if rdkit_raw_df[col].std() == 0]\n",
    "if constant_cols:\n",
    "    print(f\"Dropping constant columns: {constant_cols}\")\n",
    "    rdkit_raw_df = rdkit_raw_df.drop(columns = constant_cols)\n",
    "\n",
    "# Check for duplicate feature columns\n",
    "rdkit_raw_df = rdkit_raw_df.loc[:, ~rdkit_raw_df.T.duplicated()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7fb9e78-a3b5-4a3d-8b42-5206d82a1377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 58 extreme-skew/kurtosis columns.\n",
      "Final df shape pre-filtering: (2849, 144)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Look into skew and kurtosis and drop columns with extremes\n",
    "feature_cols = rdkit_raw_df.drop(columns = 'active')\n",
    "\n",
    "# Calculate skew and kurtosis\n",
    "skews = feature_cols.apply(skew)\n",
    "kurtoses = feature_cols.apply(kurtosis)\n",
    "\n",
    "# Define thresholds (while being generous)\n",
    "skew_thresh = 8\n",
    "kurt_thresh = 20\n",
    "\n",
    "# Identify highly skewed/kurtotic columns\n",
    "bad_skew_cols = skews[skews.abs() > skew_thresh].index\n",
    "bad_kurt_cols = kurtoses[kurtoses.abs() > kurt_thresh].index\n",
    "\n",
    "# Union of both\n",
    "bad_dist_cols = list(set(bad_skew_cols) | set(bad_kurt_cols))\n",
    "\n",
    "# Dropt these from our df\n",
    "rdkit_raw_df.drop(columns = bad_dist_cols, inplace = True)\n",
    "\n",
    "print(f\"Dropped {len(bad_dist_cols)} extreme-skew/kurtosis columns.\")\n",
    "print(f\"Final df shape pre-filtering: {rdkit_raw_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc3fac-4e0c-4d62-94be-780dcb175fd1",
   "metadata": {},
   "source": [
    "#### Good, through a few quick cleanup methods we were able to eliminate almost 70 features before we even get to our more thorough feature filtering techniques.  That will help a lot in reducing the clutter these forthcoming methods sift through to get proper results pre-modeling stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656681c-7435-47eb-93d4-ace5b31ca859",
   "metadata": {},
   "source": [
    "#### Now we will prep for our feature filtering methods, merging our QSAR features with our previous work and getting our X, y ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e0d0ca-758e-4358-98a3-6a49cca8058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2849, 149)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, RFECV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Concat QSAR features with our rdkit_raw_df\n",
    "qsar_cols = ['mw_freebase', 'alogp', 'hbd', 'hba', 'rtb', 'qed_weighted']\n",
    "qsar_df = phase1_df_fp[qsar_cols].reset_index(drop = True)\n",
    "rdkit_df = rdkit_raw_df.reset_index(drop = True)\n",
    "\n",
    "# Build X for our filtering methods\n",
    "X = pd.concat([qsar_df, rdkit_df.drop(columns = 'active')], axis = 1)\n",
    "y = rdkit_df['active'].values\n",
    "\n",
    "print(X.shape) # Should be 149 features (143 -1 + 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a812be42-625d-460f-b4a9-c1eb34f778bf",
   "metadata": {},
   "source": [
    "#### We will perform one more check if you will before we get into our fitering methods now that we have brought our features together.  We will look for multicollinearity between our features, establish a list, and then drop one from each pair generated.  Doing this will help out a lot when we get to our filtering methods, reducing errors derived from running the methods themselves (divide by 0, a popular one), will really improve the results we get when filtering and allow the filtering methods to sift through what would be otherwise unnecessary or redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f5b705-9f7b-4895-a3a2-eb3672d43f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 44 highly correlated features (r > 0.9):\n",
      "(2849, 105)\n"
     ]
    }
   ],
   "source": [
    "# Correlation-based pruning to eliminate multicollinearity\n",
    "def pairs_based_collinearity_pruning(df, threshold = 0.9):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > threshold)]\n",
    "    print(f\"Dropping {len(to_drop)} highly correlated features (r > {threshold}):\")\n",
    "    return df.drop(columns = to_drop), to_drop\n",
    "\n",
    "X_pruned, dropped_corr_cols = pairs_based_collinearity_pruning(X, threshold = 0.9)\n",
    "\n",
    "print(X_pruned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd151854-0aa4-4328-89cb-e637f537a770",
   "metadata": {},
   "source": [
    "#### This is a good result, 0.9 threshold is considered standard and we removed about 29% of our highly collineated features in performing this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea193923-9598-442b-b8af-bfe48d8ac312",
   "metadata": {},
   "source": [
    "#### We will now (finally) look at further feature filtration techniques such as VIF (Variance Inflation Factor), RFE (Recursive Feature Elimination), and MI Scoring (Mutual Information), to not only further pare down the large list of remaining features but to also be able to show predictability with our active classifier before we get to modeling while maintaining a safe threshold for variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7a552-6e48-49da-9964-10bc54c1f545",
   "metadata": {},
   "source": [
    "#### First we will run the VIF (Variance Inflation Factor), with a slightly relaxed threshold.  Generally we want to keep features  with <= 10, however since we have two more filtering methods we want to use after this we don't want to be overly aggressive here.  We will start with a higher threshold to allow for a more generous pool of features for now, and can come back later if needed.\n",
    "\n",
    "#### You can see we are also using a param of a prefilter_threshold, this will cap and remove any other outstanding collineated features that weren't caught previously.  This collineation is multivariate in nature rather than 1:1 (pairs), which is what we filtered for just prior, and is why there could potentially be outstanding collineated features we need to look for through this search before we conduct our VIF filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb4721a-d352-49b6-a486-22601efa91ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Function for the VIF method, two passes here.\n",
    "def calculate_vif(X_input, threshold = 30, prefilter_threshold = 150):\n",
    "    \n",
    "    X = X_input.copy()\n",
    "\n",
    "    # Initial scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns = X.columns)\n",
    "\n",
    "    # Compute initial VIF scores\n",
    "    vif_scores = pd.Series(\n",
    "        [variance_inflation_factor(X_scaled_df.values, i) for i in range(X_scaled_df.shape[1])],\n",
    "        index = X.columns\n",
    "    )\n",
    "\n",
    "    # Drop features with extremely high VIF first\n",
    "    high_vif_features = vif_scores[vif_scores > prefilter_threshold].index.tolist()\n",
    "    if high_vif_features:\n",
    "        print(f\"Removing high-VIF features > {prefilter_threshold} : {high_vif_features}\")\n",
    "        X.drop(columns = high_vif_features, inplace = True)\n",
    "\n",
    "    # Recalculate VIF after dropping extreme features\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns = X.columns)\n",
    "\n",
    "    vif_scores = pd.Series(\n",
    "        [variance_inflation_factor(X_scaled_df.values, i) for i in range(X_scaled_df.shape[1])],\n",
    "        index = X.columns\n",
    "    )\n",
    "\n",
    "    # Keep only features with VIF < threshold (30)\n",
    "    filtered_cols = vif_scores[vif_scores < threshold].index.tolist()\n",
    "\n",
    "    return filtered_cols, vif_scores\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0aaee82-1683-418b-8883-2cfbd193b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing high-VIF features > 150 : ['mw_freebase', 'BertzCT', 'HallKierAlpha', 'SMR_VSA10', 'SMR_VSA5', 'SMR_VSA7', 'SlogP_VSA12', 'TPSA', 'EState_VSA4', 'EState_VSA5', 'EState_VSA7', 'EState_VSA8', 'VSA_EState1', 'VSA_EState2', 'NOCount', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHeteroatoms', 'NumHeterocycles', 'RingCount']\n",
      "(2849, 67)\n"
     ]
    }
   ],
   "source": [
    "# Run the function on X_pruned\n",
    "vif_filtered_cols, vif_scores = calculate_vif(X_pruned, threshold = 30, prefilter_threshold = 150)\n",
    "X_vif = X_pruned[vif_filtered_cols] # final VIF-filtered dataframe\n",
    "\n",
    "print(X_vif.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163dfbc6-9009-46a5-8a4a-af9d37e0b8c6",
   "metadata": {},
   "source": [
    "#### Good, we did a lot of work there to not only further reduce collinearity in removing another 38 redundant features (that's a further 36%) we filtered again based on variance with a threshold of 30 to have a nice grouping going forward for RFE.  Regarding the error, it should no longer be an issue as we move forward.\n",
    "\n",
    "#### Let's move forward with the RFE (Recursive Feature Elimination) method now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a52d3f-3c33-479a-8340-9677b76d9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Build the base model to use in XGBClassifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators = 200,\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 7,\n",
    "    min_child_weight = 5,\n",
    "    random_state = 42,\n",
    "    eval_metric = 'logloss',\n",
    "    n_jobs = 1\n",
    ")\n",
    "\n",
    "# 5-fold Stratified CV\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245ab6c-ff36-46be-a159-c32a4833fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the RFECV\n",
    "rfecv = RFECV(\n",
    "    estimator = xgb_model,\n",
    "    step = 1,\n",
    "    cv = cv,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 1,\n",
    "    verbose = 1,\n",
    "    min_features_to_select = 15 # We want to keep at least 15 for MI Scoring selection\n",
    ")\n",
    "\n",
    "# Fit our selector\n",
    "rfecv.fit(X_vif, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81702b-c6f9-444e-b982-b563b6a80054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire results\n",
    "rfecv.support_\n",
    "\n",
    "rfecv_features = X_vif.columns[rfecv.support_].tolist()\n",
    "X_rfecv = X_vif[rfecv_features]\n",
    "\n",
    "print(f\"RFECV retained {len(rfecv_features)} features out of {X_vif.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f1393-07d7-44b4-815f-528b3bf99148",
   "metadata": {},
   "source": [
    "#### This is great, we have 20 features all the way down from where we started.  We are almost done here.  RFECV stands out as a good filtering method as it is filters based on model performance (XGBoost here) and we cross-validated for our metric in ROC-AUC which will be a good downstream metric to keep our eyes on as we move through this project.\n",
    "\n",
    "#### So we have filtered for variance and for the potential model performance, we just need to filter for predictability.  That's where MI Scoring will come into play now with our third and last filtering method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e464d-6d86-428a-99cc-38afcd0e2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Compute MI Scores for each of the remaining RFECV-selected features\n",
    "mi_scores = mutual_info_classif(X_rfecv, y, random_state = 42)\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature' : X_rfecv.columns,\n",
    "    'MI_Score' : mi_scores\n",
    "}).sort_values(by = 'MI_Score', ascending = False)\n",
    "\n",
    "# Apply threshold to show minor filter here\n",
    "mi_threshold = 0.03\n",
    "final_features = mi_df[mi_df['MI_Score'] > mi_threshold]['feature'].tolist()\n",
    "\n",
    "X_final = X_rfecv[final_features]\n",
    "\n",
    "# Plot our results\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.bar(mi_df['feature'], mi_df['MI_Score'])\n",
    "plt.axhline(y = mi_threshold, color = 'green', linestyle = '--', label = 'Threshold')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel('Mutual Information Score')\n",
    "plt.xlabel('Feature Importance via Mutual Information')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb64c6-b5c0-45a4-95fa-0f5b23f11afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb5cea-d770-4aeb-b01b-7090fdc7ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a7b2e-b58e-4a1f-a7a5-8f3c883b7c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e68a5-ae22-4197-b2a9-f3ab80969997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe3280-f79a-4474-af3c-cf4f06d3f144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db33350-1e68-4fff-a74a-df8abe944418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05068f-9b07-4362-993c-0d7e40c074c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
